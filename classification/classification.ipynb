{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Exercise - MNIST Number Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries & MNIST data from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import warnings\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y=mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine data visually\n",
    "\n",
    "We can look at how the 784-featured array would look like visually by looking at a single data point. It can be reshaped into a 28x28 square matrix and then plotted using the matplot binary mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1152f4da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit=X[27553]\n",
    "some_digit_image=some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_image,cmap=matplotlib.cm.binary,interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to be the number 5. It can be confirmed by looking at the target value at the corresponding data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[27553]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test set.\n",
    "\n",
    "The 70000 datapoints can be split into a 60000 training set and 10000 test set as follows. We will also shuffle the training data to ensure that we get the fairest training model (make sure to shuffle so that you don't end up having too many of the same digits and too few of the others.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest=X[:60000],X[60000:],y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index=np.random.permutation(60000)\n",
    "Xtrain,ytrain=Xtrain[shuffle_index],ytrain[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Binary Classifier\n",
    "\n",
    "We are going to train a binary classifier on a single number, say 4. We will use this to prove why accuracy may not be the best performance metric in this situation. \n",
    "\n",
    "The classifier model used will be Stochastic Gradient Descent. SGD has the advantage of being capable of handling very larget datasets efficiently (because it handles training instances independently; it's well suited for online learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_4 = (ytrain==4)\n",
    "ytest_4 = (ytest==4)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf=SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(Xtrain,ytrain_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD classifier was fit to predict true for all 4's and false for otherwise. Since our single data point *some_digit* was 4, it was predicted to be true. (It guessed correctly) \n",
    "\n",
    "## Performance Measures\n",
    "\n",
    "### 1. Accuracy\n",
    "\n",
    "Now we can measure how well SGD does by using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97630118,  0.97145   ,  0.97939897])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf,Xtrain,ytrain_4,cv=3,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests show over 95% accuracy. But is the SGD really that much accurate? To prove not so, we will test the other side; the model to test whether a number is **not** 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90325,  0.9008 ,  0.90385])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never4Classifier(BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "    \n",
    "never4_clf = Never4Classifier()\n",
    "cross_val_score(never4_clf,Xtrain,ytrain_4,cv=3,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of predicting a \"not 4\" is still over 90%. Why is this true? Because the data is pretty balanced in terms of how many each digit is represented. Therefore, there are about 90% of the whole data that are *not 4*. So even with a simple classifier that predicts not 4 for all dataset, it will be at 90% accurate. \n",
    "\n",
    "This tells us that Accuracy is not necessarily the best performance measurement for classifiers **especially with skewed dataset**.\n",
    "\n",
    "### 2. Confusion Matrix\n",
    "\n",
    "Instead, we can evaluate using the *confusion matrix*. Confusion matrix is a matrix that shows the number of instances in which an instance \"A\" was classified as instance \"B\". For example in our dataset, if a model predicts a \"5\" as a \"3\", we would look at the 5th row and 3rd column of the confusion matrix and see that prediction tallied.\n",
    "\n",
    "We will run a SGD in cross validation and then produce a confusion matrix based on our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53205,   953],\n",
       "       [  504,  5338]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ytrain_pred=cross_val_predict(sgd_clf,Xtrain,ytrain_4,cv=3)\n",
    "confusion_matrix(ytrain_4,ytrain_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix tells us the following:\n",
    "* 53205 of the non-4's were predicted as a non-4 (*True Negative*)\n",
    "* 953 of the non-4's were incorrectly predicted as a 4 (*False Positive*)\n",
    "* 504 of the 4's were incorrectly predicted as a non-4 (*False Negative*)\n",
    "* 5338 of the 4's were predicted as a 4 (*True Positive*)\n",
    "\n",
    "Based on the confusion matrix, we derive two basic metrics: *precision* and *recall*. \n",
    "\n",
    "* Precision measures the accuracy of the positive predictions: $$Precision = \\frac{TP}{TP+FP}$$\n",
    "* Recall measures the ratio of positives that are correctly detected: $$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "### 3. Precision/Recall\n",
    "\n",
    "Now we can implement the Precision and Recall to see some more suitable metrics for the SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.848513749801\n",
      "Recall:  0.913728175282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(\"Precision: \", precision_score(ytrain_4,ytrain_pred))\n",
    "print(\"Recall: \", recall_score(ytrain_4,ytrain_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by hand:  0.8485137498013035\n",
      "Recall by hand:  0.9137281752824375\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by hand: \", 5338/(5338+953))\n",
    "print(\"Recall by hand: \", 5338/(5338+504))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new metrics show that the classifier is only 91% accurate predicting the digit 4 correctly, and 84% correct when it predicts a digit as a 4 (well below 97% measured in pure accuracy). \n",
    "\n",
    "It is often convenient to combine *Precision* and *Recall* into a single metric called *F1 score*. *F1 score* is the harmonic mean of precision and recall: \n",
    "$$F_1 = \\frac{2*precision*recall}{precision+recall} =\\frac{TP}{TP+\\frac{FN+FP}{2}}$$\n",
    "\n",
    "We can implement the F1 score using the sklearn function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87991428335943289"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(ytrain_4,ytrain_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
